---
title: "Logistic-Lasso Coordinate Descent Algorithm"
author: "Jimmy Kelliher (UNI: jmk2303)"
date: "2022-03-20"
output: pdf_document
---

```{r setup, include=FALSE}
source("shared_code/setup.R")
library(glmnet)
```

# Theory

__Lemma 1.__ Consider the optimization problem
  \[ \min_{x \in \mathbb{R}}  \left\{ \frac{1}{2}(x - b)^2 + c|x| \right\} \]
for $b \in\mathbb{R}$ and $c \in \mathbb{R}_{++}$. It follows that the minimizer is given by
  \[ \hat{x} = S(b, c), \]
where $S$ is the soft-thresholding operator.

__Lemma 2.__ Consider the optimization problem
  \[ \min_{\beta_k \in \mathbb{R}} \left\{ \frac{1}{2n} \sum_{i = 1}^n w_i \left(z_i - \sum_{j = 1}^p \beta_j x_{ij} \right)^2 \right\} \]
for some $k \in \{ 1, \ldots, p \}$. It follows that the minimizer is given by
  \[ \hat{\beta}_k = \left( \sum_{i = 1}^n w_i x_{ik}^2 \right)^{-1} \sum_{i = 1}^n w_i x_{ik} \left(z_i - \sum_{j \neq k} \beta_j x_{ij} \right). \]

__Lemma 3.__ With $\hat{\beta}_k$ defined as above,
  \[ \min_{\beta_k \in \mathbb{R}} \left\{ \frac{1}{2n} \sum_{i = 1}^n w_i \left(z_i - \sum_{j = 1}^p \beta_j x_{ij} \right)^2 + \lambda \sum_{j = 1}^p |\beta_j| \right\}
  = \min_{\beta_k \in \mathbb{R}} \left\{ \frac{1}{2}(\beta_k - \hat{\beta}_k)^2 + \left( \frac{1}{n} \sum_{i = 1}^n w_i x_{ik}^2 \right)^{-1} \lambda |\beta_k| \right\}. \] 

__Proposition.__ By Lemma 1 and Lemma 3,
  \[ \underset{\beta_k \in \mathbb{R}}{\arg \min} \left\{ \frac{1}{2n} \sum_{i = 1}^n w_i \left(z_i - \sum_{j = 1}^p \beta_j x_{ij} \right)^2 + \lambda \sum_{j = 1}^p |\beta_j| \right\}
  = S \left(\hat{\beta}_k, \left( \frac{1}{n} \sum_{i = 1}^n w_i x_{ik}^2 \right)^{-1} \lambda \right) \]

\newpage
# Praxis

```{r}
data <-
  read_csv("data/breast-cancer.csv", show_col_types = FALSE) %>%
  mutate(diagnosis = 1 * (diagnosis == "M"))
```

## Helper Functions

```{r}
# logistic function
logistic <- function(x) 1 / (1 + exp(-x))

# shrinkage function
S <- function(beta, gamma) {
  if(abs(beta) <= gamma) {
    0
  } else if(beta > 0) {
    beta - gamma
  } else {
    beta + gamma
  }
}

# probability adjustment function
p_adj <- function(p, epsilon) {
  if (p < epsilon) {
    0
  } else if(p > 1 - epsilon) {
    1
  } else {
    p
  }
}

# weight adjustment function
w_adj <- function(p, epsilon) {
  if ((p < epsilon) | (p > 1 - epsilon)) {
    epsilon
  } else {
    p * (1 - p)
  }
}
```

## Toy Example

```{r}
set.seed(1)
lambda <- 0 #0.0125
epsilon <- 10^(-5)

q    <- 30 - 1
n    <- 1000
X    <- matrix(rnorm(q * n), c(n, q))
X    <- as.matrix(cbind(rep(1, n), X))
y    <- 1 * (runif(n) > 0.5)

# initialize parameters
beta <- rep(0.25, ncol(X))

outer_term <- 0
outer <- 1
while(outer_term < 1) {

p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
w <- map_dbl(p, w_adj, epsilon)
z <- X %*% beta + (y - p) / w

  terminate <- 0
  iter <- 1
  while(terminate < 1) {
  
    beta_old <- beta
  
    for(k in 1:ncol(X)) {
      x_k    <- X[ , k]
      x_notk <- X[ , -k]
      b_notk <- beta[-k]
  
      # un-penalized coefficient update
      b_k_temp <- sum(w * (z - x_notk %*% b_notk) * x_k) / sum(w * x_k^2)
      # shrinkage update
      b_k      <- S(b_k_temp, lambda * (k > 1) / mean(w * x_k^2))
      # update beta vector along with other parameters
      beta[k] <- b_k
      #p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
      #w <- map_dbl(p, w_adj, epsilon)
      #z <- X %*% beta + (y - p) / w
    }

    iter <- iter + 1

    if(iter == 100 | max(abs(beta - beta_old)) < 10^(-12)) {
      terminate <- 1
    }

  }

  print(iter)
  outer <- outer + 1

  if(outer == 100 | iter == 2) {
      print(iter)
      outer_term <- 1
  }

}

# true estimates from glmnet
fit <- glmnet(X, y, family = "binomial", standardize = FALSE, lambda = lambda, thresh = 10^-12)

# results
results <- tibble(
    Variable   = 1:length(beta)
  , Jimmy      = beta
  , GLM        = as.vector(glm(y ~ X[ , -1], family = binomial)$coefficients)
  , GLMNET     = as.vector(fit$beta[ , ncol(fit$beta)])
  , Difference = abs(Jimmy - GLMNET)
  , Change     = (Jimmy - GLMNET) / GLMNET
) %>%
  mutate(GLM = na_if(GLM, (lambda != 0) * GLM)) %>%
  filter(Jimmy != 0 | GLMNET != 0)
results %>% knitr::kable()
```

## Test with Actual Data

```{r}
set.seed(1)
epsilon <- 10^(-5)

n    <- nrow(data)
X    <- scale(data[ , -c(1, 2)])
#X    <- data[ , -c(1, 2)]
X    <- as.matrix(cbind(rep(1, n), X))
y    <- data$diagnosis

beta <- rep(0, ncol(X))
lambda_vec <- 1 - log(seq(exp(0.001), exp(1), 0.01))
lambda_vec <- exp(seq(log(0.4), log(0.0004), -0.1))
lambda_vec <- c(0.4, 0.38, 0.36)

for(lambda in lambda_vec) {
# (max(t(X) %*% y) / n)

for(outer in 1:3) {

# initialize parameters
#p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
#w <- map_dbl(p, w_adj, epsilon)
#z <- X %*% beta + (y - p) / w

terminate <- 0
iter <- 1
while(terminate < 1) {

  p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
  w <- map_dbl(p, w_adj, epsilon)
  z <- X %*% beta + (y - p) / w

  beta_old <- beta
  # initially go through all parameters
  K <- 1:ncol(X)
  #if(iter > 1) {
  #  K <- which(beta > 0)
  #}

  for(k in K) {
    x_k    <- X[ , k]
    x_notk <- X[ , -k]
    b_notk <- beta[-k]

    # un-penalized coefficient update
    b_k_temp <- sum(w * (z - x_notk %*% b_notk) * x_k) / sum(w * x_k^2)
    # shrinkage update
    b_k      <- S(b_k_temp, lambda * (k > 1) / mean(w * x_k^2))

    # update beta vector along with other parameters
    beta[k] <- b_k
    #p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
    #w <- map_dbl(p, w_adj, epsilon)
    #z <- X %*% beta + (y - p) / w
  }

  iter <- iter + 1

  if(iter == 1000 | max(abs(beta - beta_old)) < 10^-12) {
    print(iter)
    terminate <- 1
  }

}

}

# True estimates from GLMNET
fit <- glmnet(X, y, family = "binomial", standardize = FALSE, lambda = lambda, thresh = 10^-12)

# results
results <- tibble(
    Variable   = 1:length(beta)
  , Name       = c("intercept", names(data[ , -c(1, 2)]))
  , Jimmy      = beta
  , GLMNET     = as.vector(fit$beta[ , ncol(fit$beta)])
  , Difference = abs(Jimmy - GLMNET)
) %>%
  filter(Jimmy != 0 | GLMNET != 0)

print(paste0("lambda = ", lambda))
print(results %>% knitr::kable())
}
```










## Second Attempt with Actual Data

```{r}
epsilon <- 10^(-5)

n    <- nrow(data)
#X    <- scale(data[ , -c(1, 2)])
X    <- data[ , -c(1, 2)]
X    <- as.matrix(cbind(rep(1, n), X))
y    <- data$diagnosis

beta <- rep(0, ncol(X))
lambda_vec <- exp(seq(log(0.4), log(0.4/1000), -0.2))
lambda_vec <- rep(seq(10, 2, -1), 4) / c(rep(1, 9), rep(10, 9), rep(100, 9), rep(1000, 9))
lambda_vec <- exp(seq(log(0.4), log(0.4/10), -0.1))
lambda_vec <- seq(0.40, 0.20, -0.01)

# initialize parameters
beta <- rep(0, ncol(X))
beta_matrix <- t(c(NA, beta))

for(lambda in lambda_vec) {

  outer_term <- 0
  outer <- 1
  while(outer_term < 1) {
  
  #p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
  #w <- map_dbl(p, w_adj, epsilon)
  #z <- X %*% beta + (y - p) / w
  
    terminate <- 0
    iter <- 1
    while(terminate < 1) {
    
      beta_old <- beta

      p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
      w <- map_dbl(p, w_adj, epsilon)
      z <- X %*% beta + (y - p) / w

      for(k in 1:ncol(X)) {
        x_k    <- X[ , k]
        x_notk <- X[ , -k]
        b_notk <- beta[-k]

        # un-penalized coefficient update
        b_k_temp <- sum(w * (z - x_notk %*% b_notk) * x_k) / sum(w * x_k^2)
        # shrinkage update
        b_k      <- S(b_k_temp, lambda * (k > 1) / mean(w * x_k^2))
        # update beta vector along with other parameters
        beta[k] <- b_k
        #p <- map_dbl(logistic(X %*% beta), p_adj, epsilon)
        #w <- map_dbl(p, w_adj, epsilon)
        #z <- X %*% beta + (y - p) / w
      }

      iter <- iter + 1

      if(iter == 100 | max(abs(beta - beta_old)) < 10^(-10)) {
        terminate <- 1
      }

    }

    outer <- outer + 1
  
    if(outer == 100 | iter == 2) {
        print(lambda)
        outer_term <- 1
    }

  }

  # true estimates from glmnet
  #fit <- glmnet(
  #  X
  #  , y
  #  , family = "binomial"
  #  , standardize = FALSE
  #  , lambda = lambda
  #  , thresh = 10^-12
  #  , maxit  = 10^6
  #)

  # results
  #results <- tibble(
  #    Variable   = 1:length(beta)
  #  , Name       = c("intercept", names(data[ , -c(1, 2)]))
  #  , Jimmy      = beta
  #  , GLMNET     = as.vector(fit$beta[ , ncol(fit$beta)])
  #  , Difference = abs(Jimmy - GLMNET)
  #  , Change     = (Jimmy - GLMNET) / GLMNET
  #) %>%
  #  filter(Jimmy != 0 | GLMNET != 0)

  #print(paste0("lambda = ", lambda))
  #print(results %>% knitr::kable())

  beta_matrix <- rbind(beta_matrix, t(c(lambda, beta)))

}
```


```{r}
results %>% knitr::kable()
```