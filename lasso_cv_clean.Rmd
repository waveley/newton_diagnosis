---
title: "Lasso CV"
author: "Tucker Morgan - tlm2152"
date: "3/20/2022"
output: pdf_document
---

```{r setup, warning=FALSE, message = FALSE}
source("./shared_code/setup.R")
```

```{r data import and partition, warning=FALSE, message = FALSE}
source("./shared_code/data_prep.R")
```

```{r external-functions, warning=FALSE, message=FALSE}
source("./shared_code/logistic_lasso.R")
source("./shared_code/auc_calc_lasso.R")
```

## Folding Data

```{r folding training data}
source("./shared_code/cv_folding.R")

bc_trn_folds <- 
  cv_sets(training = bc_trn) %>% 
  select(-fold_p)
```

## Helper Functions

```{r helper-functions, warning=FALSE, message=FALSE}

identity <- function(x){
  return(x)
}

lambda_init <- function(start, stop, step, func = identity){
  lambda_vec <- func(seq(start, stop, step))
  return(lambda_vec)
}
```

## Cross Validation Function

```{r cv, warning=FALSE, message=FALSE}

#################
#
# This function takes in the following parameters:
# > k: number of folds
# > training: training dataset, first column is outcome, remaining columns are predictors.
# > lambda_list: list containing the following:
#     - lambda_start: starting value of lambda vector, without lam_start_stop_func applied
#     - lambda_stop: stopping value of lambda vector, without lam_start_stop_func applied
#     - lambda_step: step size between numbers in linear sequence
#     - lambda_func: transformation of initial sequence of numbers
#     - lambda_start_stop_func: function applied to lambda_start/lambda_stop
#
#
# This function returns a list with two elements:
# > A matrix containing the results of the last CV:
#     - lambda: a column of lambdas
#     - mean_auc: mean AuC
#     - selected_vars: number of selected variables column (excluding intercept)
#     - num_dropped_Vars: number of variables deleted from previous lambda
# > A matrix containing the lambda vectors that were attempted.
#     - lambda_count: id of lambda vector/iteration number
#     - lambda_start: starting value of lambda vector, *without* the lam_start_stop_func
#       applied (i.e., in linear/untransformed units)
#     - lambda_stop: stopping value of lambda vector, *without* the lam_start_stop_func 
#       applied (i.e., in linear/untransformed units)
#     - lambda_step: step size between lambdas
#       if lambda_start > lambda_stop, this should be negative.
#
#################

cv_jt <- function(k = 5, training, func, lam_start_stop_func, lambda_list){
  
  lam_start <- lambda_list[[1]]
  lam_stop <- lambda_list[[2]]
  lam_step <- lambda_list[[3]]
  lam_func <- lambda_list[[4]]
  
  lam_list <- tibble(
    lam_count = 0,
    lam_start = 0,
    lam_stop = 0,
    lam_step = 0
  )
  
  lam_count <- 0
  del_too_many_var <- 1
  out_res <- list()
 
 while (del_too_many_var > 0) {
     # print("working")
      
     lam_count <- lam_count + 1
     
      # saving lambda vector parameters
     cur_lam_list <- tibble(lam_count, lam_start, lam_stop, lam_step)
     
     lam_list <- bind_rows(lam_list, cur_lam_list) 
     
     new_lambda_vec <- lambda_init(lam_start, lam_stop, lam_step, lam_func)
     
     lasso_list <- list()
     auc_list <- list()
    
     pb <- progress_bar$new(
        format = " lasso-ing [:bar] :percent eta: :eta",
        total = 5, clear = FALSE, width = 60)
     
      for (i in 1:k) {
     
            pb$tick()
            
            # this will identify the training set as not i
            trn_set = 
              training %>% 
              filter(fold_id != i) %>% 
              select(-fold_id)
            
            # and this assigns i to be the test set
            tst_set =
              training %>% 
              filter(fold_id == i) %>% 
              select(-fold_id) %>%
              rename(y = diagnosis)
            
            # making matrices
            X_trn <- trn_set[,-1]
            Y_trn <- trn_set$diagnosis
            
            #print("about to lasso")
            
            # lasso_list    
            lasso_list <- func(inputs = X_trn, output = Y_trn, lambda_vec = new_lambda_vec)
            
            #print("done with lasso")
            
            lasso_lambda <- lasso_list[[1]]
            lasso_beta <- lasso_list[[2]]
            lasso_selected <- tibble(selected_num = lasso_list[[3]])
            
            lasso_lam_bet <- cbind(lasso_lambda, lasso_beta) %>% as.matrix()
          
            trn_roc <- auc_calc_lasso(lasso_lam_bet, tst_set)
            auc_list <- bind_rows(auc_list, trn_roc)
        
          }
          
        auc_res <- 
          auc_list %>% 
          group_by(lambda) %>%
          summarise(mean_auc = mean(auc_vals))
         
        res <- bind_cols(auc_res, lasso_selected)
        
        res <- res %>% 
          mutate(num_dropped_vars = selected_num - lag(selected_num, 1))
        
        del_too_many_var <- sum(na.omit(res$num_dropped_vars) > 1)
        
        # del_too_many_var <- 0
        
          if (del_too_many_var > 0) {
            max_auc_lam <- res %>% filter(mean_auc == max(mean_auc)) %>% pull(lambda) %>% mean()
            lam_start <- lam_start_stop_func(max_auc_lam) + 2*abs(lam_step)
            lam_stop <- lam_start_stop_func(max_auc_lam) - 2*abs(lam_step)
            lam_step <- sign(lam_step)*(lam_start - lam_stop)/length(new_lambda_vec)
          }  
 }
  
  # creating dataframe to show lambda values and corresponding mean AUC
  out_res[[1]] <- res
  out_res[[2]] <- lam_list
 
  return(out_res)
}

# test lambda list
#lambda_list <- list(0.4, 0.20, -0.01, identity)

# identify minimum lambda value for which all coefficients are zero
# 
# set lambda_min based on scaled data
# lambda_min <- 0.0001
# define vector of lambdas
# lambda_seq <- exp(seq(log(lambda_max), log(lambda_min), length.out = 100))

lambda_max <- max(t(scale(as.matrix(bc_trn[,-1]))) %*% bc_trn[,1]) / nrow(bc_trn[,-1])

lambda_list <- list(log(lambda_max), log(0.0001), -(log(lambda_max) - log(0.0001))/100, exp)

cv_res <- cv_jt(k = 5, training = bc_trn_folds, func = logistic_lasso, lam_start_stop_func = log, lambda_list = lambda_list)

cv_res[[1]] %>% knitr::kable()
cv_res[[2]] %>% knitr::kable()
```

## Final Lasso-Logistic Model with Selected Lambda

```{r}
# selected lambda: 0.05118004
selected_lambda <- cv_res[[1]] %>% filter(mean_auc == max(mean_auc)) %>% pull(lambda)
lasso_final_model <- logistic_lasso(inputs = bc_trn[,-1], output = bc_trn[,1], lambda_vec = selected_lambda)
save(lasso_final_model, file = "lasso_results_wq.Rdata")
lasso_betas <- lasso_final_model[[2]] %>% t()
```

# Lasso AUC

```{r}
auc_calc_full <- function(beta_est, test_data){
  # pulling out the terms used in the full model (should be all)
  
  # we have this flexible in case we want to test fewer variables 
  # terms <- beta_est %>% pull(term) 
  # col.num <- which(colnames(test_data) %in% terms)
  # select the desired x values 
  test_data = bc_tst
  xvals <- test_data[,-1] %>% 
     mutate(
      intercept = 1 # create a intercept variable 
    ) %>%
    relocate(intercept) # move it to the front 
  pred <- as.matrix(xvals) %*% beta_est # get the cross product of the linear model
  logit_pred <- exp(pred) / (1 + exp(pred)) # link function to get probabilities
  
  auc_val <- auc(test_data[,1], as.vector(logit_pred)) # calculating the AUC
  
  # roc(tst_data$y, as.vector(logit_pred)) %>% plot( legacy.axes=TRUE) # graphs AUC
  return(auc_val)

}

lasso_auc <- auc_calc_full(lasso_betas, bc_tst)
```

The AUC of the logistic-lasso model is `r lasso_auc`.

