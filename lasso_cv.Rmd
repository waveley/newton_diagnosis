---
title: "Lasso CV"
author: "Tucker Morgan - tlm2152"
date: "3/20/2022"
output: pdf_document
---

```{r setup, message = FALSE}
library(tidyverse)
library(glmnet)
```

```{r data import and partition, message = FALSE}
bc <- 
  read_csv("./data/breast-cancer.csv") %>% 
  mutate(diagnosis = 1 *(diagnosis == "M")) %>% 
  select(-id)

source("./shared_code/partition.R")

part_bc <- partition(p = 0.8, data = bc)

bc_trn <- 
  part_bc %>% 
  filter(part_id == "train") %>% 
  select(-part_id)

bc_tst <- 
  part_bc %>% 
  filter(part_id == "test") %>% 
  select(-part_id)
```

```{r folding training data}
source("./shared_code/cv_folding.R")

bc_trn_folds <- 
  cv_sets(training = bc_trn) %>% 
  select(-fold_p)
```

```{r cv implementation, message = FALSE, warning = FALSE}
set.seed(100)

X <- bc_trn_folds[, -c(1,32)]
X <- as.matrix(X)
Y <- bc_trn_folds$diagnosis
lambda_vec <- seq(0, 0.4, length = 5) # lambda vector for testing

# creating a simple example function for testing
ex_func <- function(x, y, lambda_vec){
  glmnet(x = x, y = y,
         standardize = TRUE,
         alpha = 1,
         lambda = lambda_vec,
         family = "binomial"(link = "logit"))
}

ex_func(x = X, y = Y, lambda_vec = 0) %>% coef() # just for example, not stored

cv_function <- function(k = 5, training, func, lambda_vec){
  
  auc_list = list()
  mean_auc_list = list()
# first, a for loop to iterate over a lambda vector
  for (j in 1:length(lambda_vec)){
    # and now we have a for loop to iterate over each fold, k = 5 here
    for (i in 1:k){
      # this will identify the training set as not i
      trn_set = 
        training %>% 
        filter(fold_id != i) %>% 
        select(-fold_id)
      # and this assigns i to be the test set
      tst_set =
        training %>% 
        filter(fold_id == i) %>% 
        select(-fold_id)
      # making matrices
      X_trn <- as.matrix(trn_set[,-1])
      X_tst <- as.matrix(tst_set[,-1])
      Y_trn <- trn_set$diagnosis
      # fitting our function based on training set
      trn_fit = func(x = X_trn, y = Y_trn, lambda_vec = lambda_vec[j])
      # calculating AUC
      trn_pred <- predict(trn_fit,
                          newx = X_tst,
                          type = "response")
      trn_roc <- pROC::roc(tst_set$diagnosis, trn_pred)
      
      auc_list[[i]] = trn_roc$auc
    }
    # calculating mean cv auc for each lambda
    auc_df = data.frame("auc" = do.call(rbind, auc_list))
    mean_auc = mean(auc_df$auc)
    mean_auc_list[[j]] = data.frame("mean_auc" = mean_auc, "lambda" = lambda_vec[j])
  }
  # creating dataframe to show lambda values and corresponding mean AUC
  res = as.data.frame(do.call(rbind, mean_auc_list))
  
  return(res)
}

cv_function(training = bc_trn_folds, func = ex_func, lambda_vec = lambda_vec)
```

The cross-validation function seems to work as intended, but I found that the mean AUC dropped to 0.5 (no discrimination) at a seemingly low lambda value of 0.4. I'll run `glmnet` below to show that all coefficients drop out at lambda = 0.4.

```{r glmnet example}
glmnet(x = X, y = Y,
       standardize = TRUE,
       alpha = 1,
       lambda = 0.4,
       family = "binomial"(link = "logit")) %>% 
  coef()
```

Bizarre!